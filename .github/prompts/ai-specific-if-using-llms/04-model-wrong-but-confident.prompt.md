Plan for the scenario where the model is wrong but confident.

Instructions
- Enumerate failure modes (incorrect facts, wrong actions, fabricated citations, overconfident recommendations).
- Define detection strategies (validation rules, cross-checking, self-consistency, retrieval verification, user feedback loops).
- Specify UX and product responses (uncertainty, disclaimers, “show your work”, escalation to human review).
- Define containment and recovery (rollback, audit logs, incident response, rate limiting).

Output
- A mitigation plan that covers detection, user experience, containment, and learning loops.
